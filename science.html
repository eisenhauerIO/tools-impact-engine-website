<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="Impact Engine — the science: causal inference, evidence quality assessment, and decision theory.">
    <title>Science | Impact Engine</title>
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Crimson+Pro:wght@300;400;600&family=Inter:wght@300;400;500;600&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <div class="container">
        <nav>
            <ul>
                <li><a href="index.html">Home</a></li>
                <li><a href="system.html">System</a></li>
            </ul>
        </nav>

        <div class="content">
            <header>
                <h1>Science</h1>
                <p class="subtitle">
                    Three questions drive the pipeline. Each maps to a discipline, a stage,
                    and a concrete output — grounded in established methods from econometrics
                    and statistical decision theory.
                </p>
            </header>

            <main>
                <h2>Causal Inference — What happened?</h2>
                <div class="section-flex">
                    <div class="section-image" style="max-width: 420px;">
                        <img src="img/counterfactual.svg"
                             alt="Timeline showing observed outcome diverging from the unobservable counterfactual after an initiative launches.">
                        <p class="diagram-caption">You can only ever observe one world. Every causal method reconstructs the one you didn't.</p>
                    </div>
                    <div class="section-text">
                        <p>
                            When metrics move after an initiative launches, other things move too — seasonality,
                            competitor actions, market shifts. The causal question is always: how much of that
                            movement was actually caused by the initiative?
                        </p>
                    </div>
                </div>
                <h4>
                    <span class="badges">
                        <a href="https://github.com/eisenhauerIO/tools-impact-engine-measure/actions/workflows/ci.yaml" target="_blank"><img src="https://github.com/eisenhauerIO/tools-impact-engine-measure/actions/workflows/ci.yaml/badge.svg" alt="CI"></a>
                        <a href="https://github.com/eisenhauerIO/tools-impact-engine-measure/actions/workflows/docs.yml" target="_blank"><img src="https://github.com/eisenhauerIO/tools-impact-engine-measure/actions/workflows/docs.yml/badge.svg?branch=main" alt="Docs"></a>
                    </span>
                    Impact Engine — Measure
                </h4>
                <p>
                    The <strong>Impact Engine — Measure</strong> manages the full measurement
                    pipeline — data loading, transformation, estimation, and storage — behind
                    a single config-driven interface. Swap the causal method, data source, or
                    storage backend by changing one line in YAML, without rewriting connectors
                    or breaking downstream consumers.
                </p>

                <h2>Evidence Assessment — What did we learn?</h2>
                <div class="section-flex">
                    <div class="section-text">
                        <p>
                            Not every causal estimate deserves the same weight. The design of a study —
                            how random the assignment, how clean the control group — determines how much
                            the resulting number can be trusted.
                        </p>
                    </div>
                    <div class="section-image" style="max-width: 420px;">
                        <img src="img/evidence-hierarchy.svg"
                             alt="Horizontal confidence bars for four causal methods, decreasing from Randomized Experiment (0.95) down to Time Series ARIMA (0.45).">
                        <p class="diagram-caption">Not all estimates are equal. The method that produced a number determines how much weight it deserves.</p>
                    </div>
                </div>
                <h4>
                    <span class="badges">
                        <a href="https://github.com/eisenhauerIO/tools-impact-engine-evaluate/actions/workflows/ci.yaml" target="_blank"><img src="https://github.com/eisenhauerIO/tools-impact-engine-evaluate/actions/workflows/ci.yaml/badge.svg" alt="CI"></a>
                        <a href="https://github.com/eisenhauerIO/tools-impact-engine-evaluate/actions/workflows/docs.yaml" target="_blank"><img src="https://github.com/eisenhauerIO/tools-impact-engine-evaluate/actions/workflows/docs.yaml/badge.svg?branch=main" alt="Docs"></a>
                    </span>
                    Impact Engine — Evaluate
                </h4>
                <p>
                    The <strong>Impact Engine — Evaluate</strong> assigns a confidence score
                    to each initiative based on its measurement design. That score directly
                    penalizes return estimates downstream: low confidence pulls returns toward
                    worst-case scenarios, making the allocator conservative where evidence is
                    weak and aggressive where evidence is strong.
                </p>

                <h2>Decision Theory — What should we do?</h2>
                <div class="section-flex">
                    <div class="section-image" style="max-width: 420px;">
                        <img src="img/portfolio-allocation.svg"
                             alt="Grouped bar chart showing confidence-adjusted returns for three initiatives across optimistic, base, and pessimistic scenarios. Initiatives A and B are selected; C is not funded due to its near-zero pessimistic return.">
                        <p class="diagram-caption">Knowing what works is not enough. You still have to decide where to bet.</p>
                    </div>
                    <div class="section-text">
                        <p>
                            Causal estimates and confidence scores answer what happened. They don't answer
                            what to fund. Decision theory frames allocation as a portfolio problem and
                            resolves it under uncertainty.
                        </p>
                    </div>
                </div>
                <h4>
                    <span class="badges">
                        <a href="https://github.com/eisenhauerIO/tools-impact-engine-allocate/actions/workflows/ci.yaml" target="_blank"><img src="https://github.com/eisenhauerIO/tools-impact-engine-allocate/actions/workflows/ci.yaml/badge.svg" alt="CI"></a>
                        <a href="https://github.com/eisenhauerIO/tools-impact-engine-allocate/actions/workflows/docs.yaml" target="_blank"><img src="https://github.com/eisenhauerIO/tools-impact-engine-allocate/actions/workflows/docs.yaml/badge.svg?branch=main" alt="Docs"></a>
                    </span>
                    Impact Engine — Allocate
                </h4>
                <p>
                    The <strong>Impact Engine — Allocate</strong> solves this with two
                    pluggable decision rules. Minimax regret minimizes the maximum regret
                    across all scenarios. A Bayesian solver maximizes expected return under
                    user-specified scenario weights. Both consume confidence-penalized
                    returns — better evidence enables better bets.
                </p>

                <hr>
                <h2>Further Reading</h2>
                <p>For the maintainer's publications, teaching, and applied work on these methods, see <a href="https://peisenha.github.io" target="_blank">Philipp Eisenhauer</a>.</p>

                <h4>Causal Inference</h4>
                <p>J.D. Angrist &amp; J.S. Pischke — <em>Mostly Harmless Econometrics</em> (2009)</p>
                <p>G.W. Imbens &amp; D.B. Rubin — <em>Causal Inference for Statistics, Social, and Biomedical Sciences</em> (2015)</p>

                <h4>Evidence Assessment</h4>
                <p>W.R. Shadish, T.D. Cook &amp; D.T. Campbell — <em>Experimental and Quasi-Experimental Designs for Generalized Causal Inference</em> (2002)</p>
                <p>A.S. Gerber &amp; D.P. Green — <em>Field Experiments: Design, Analysis, and Interpretation</em> (2012)</p>

                <h4>Decision Theory</h4>
                <p>J.O. Berger — <em>Statistical Decision Theory and Bayesian Analysis</em> (1985)</p>
                <p>A. Wald — <em>Statistical Decision Functions</em> (1950)</p>

                <a href="index.html" class="back-link">
                    <svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
                        <path d="M19 12H5M12 19l-7-7 7-7"/>
                    </svg>
                    Back to Home
                </a>
            </main>
        </div>
    </div>
</body>
</html>
